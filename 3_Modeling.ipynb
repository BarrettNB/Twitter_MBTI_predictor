{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer#, ENGLISH_STOP_WORDS\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "# import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "LIBPATH = r'D:\\Springboard_DataSci\\Assignments\\Lib'\n",
    "if LIBPATH not in sys.path:\n",
    "    sys.path.insert(0, LIBPATH)\n",
    "import TimeTracker\n",
    "\n",
    "TYPE = 'Type'\n",
    "LOGISTIC = 'logistic'\n",
    "NAIVE_BAYES = 'multinomial naive Bayes'\n",
    "RAND_FOREST = 'random forest'\n",
    "\n",
    "# Get all the tweets.\n",
    "path = r'D:\\Springboard_DataSci\\Twitter_MBTI_predictor\\Data Output'\n",
    "os.chdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "letters = [['E', 'I'], ['S', 'N'], ['F', 'T'], ['J', 'P']]\n",
    "MB_types = []\n",
    "# Get the list of types using binary math.\n",
    "for i in range(16):\n",
    "    MB_types.append(letters[0][i//8%2] + letters[1][i//4%2]\n",
    "                      + letters[2][i//2%2] + letters[3][i%2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tweets(MB_type):\n",
    "    return pd.read_csv(\n",
    "        path + '\\\\' + MB_type + '_tweets.csv', parse_dates=[2],\n",
    "        infer_datetime_format=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tweets: ESFJ ESFP ESTJ ESTP ENFJ ENFP ENTJ ENTP ISFJ ISFP ISTJ ISTP INFJ INFP INTJ INTP "
     ]
    }
   ],
   "source": [
    "# Load tweets\n",
    "print('Loading tweets:', end=' ')\n",
    "for i, MB_type in enumerate(MB_types):\n",
    "    print(f'{MB_type}', end=' ')\n",
    "    if i == 0:\n",
    "        tweets = load_tweets(MB_type)\n",
    "    else:\n",
    "        tweets = tweets.append(load_tweets(MB_type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify their type\n",
    "for i, letter in enumerate('ESFJ'):\n",
    "    tweets[letter] = tweets['MBTI'].str[i] == letter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to pick up a lot of junk if we don't trim out tags and hashtags.\n",
    "Let's do that now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_tweet(tweet):\n",
    "    return ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\",\n",
    "                           \" \", tweet).split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trimming tweets of tags and URLs\n"
     ]
    }
   ],
   "source": [
    "print('\\nTrimming tweets of tags and URLs')\n",
    "tweets['Tweet'] = tweets['Tweet'].apply(trim_tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's attempt to classify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_tweets(tweets, letter, classifier, min_df=200, max_df=1.,\n",
    "                   alpha=1, C=1, max_depth=None, n_estimators=100,\n",
    "                   stop_words=None, get_words_and_probas=False, test_size=0.25,\n",
    "                   max_iter=1e3):\n",
    "    '''Text classification of the tweets'''\n",
    "    y = tweets[letter]\n",
    "    vectorizer = CountVectorizer(min_df=min_df, max_df=max_df,\n",
    "                                 stop_words=stop_words)\n",
    "    tweets = tweets['Tweet'].to_list()\n",
    "    # Get the sparse matrix (x, y) of (tweetID, wordID).\n",
    "    X = vectorizer.fit_transform(tweets)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=0)\n",
    "    \n",
    "    if classifier==LOGISTIC:\n",
    "        clf = LogisticRegression(C=C, max_iter=max_iter, random_state=0)\\\n",
    "            .fit(X_train, y_train)\n",
    "    elif classifier==NAIVE_BAYES:\n",
    "        clf = MultinomialNB(alpha=alpha).fit(X_train, y_train)\n",
    "    elif classifier==RAND_FOREST:\n",
    "        clf = RandomForestClassifier(\n",
    "            n_estimators=n_estimators, max_depth=max_depth, random_state=0)\\\n",
    "            .fit(X_train, y_train)\n",
    "    else:\n",
    "        raise ValueError('Unrecognized classifier \"' + classifier + '\"')\n",
    "        \n",
    "    if get_words_and_probas:\n",
    "        x = np.eye(X_test.shape[1])\n",
    "        words_all = np.array(vectorizer.get_feature_names())\n",
    "        probs = clf.predict_log_proba(x)[:, 0]\n",
    "    else:\n",
    "        words_all = probs = None\n",
    "    return clf.score(X_train, y_train), clf.score(X_test, y_test), words_all,\\\n",
    "        probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grouping tweets by author\n"
     ]
    }
   ],
   "source": [
    "print('Grouping tweets by author')\n",
    "tweets_per_author = tweets.copy()\n",
    "tweets_per_author['Tweet'] = tweets_per_author['Tweet']\\\n",
    "    .apply(lambda x: x + ' ')\n",
    "tweets_per_author = tweets_per_author.groupby(\n",
    "    tweets_per_author['Screen name'])['Tweet'].apply(lambda x: x.sum())\\\n",
    "    .reset_index()\n",
    "# This threw away the MBTI info, but we can get it back.\n",
    "authors_MBTI = tweets[['Screen name', 'E', 'S', 'F', 'J']].drop_duplicates()\n",
    "tweets_per_author = tweets_per_author.merge(\n",
    "    authors_MBTI, 'left', on='Screen name')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've looked through several combinations of hyperparameters. Let's look\n",
    "for the one that performs the best on each axis. We search by axis (letter),\n",
    "min_df, classifier, and hyperparameter. We look for the best test score per\n",
    "run and record it. This testing includes random forests, which we have not\n",
    "looked at yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing tweets at the author level: E/I\n",
      "\tBest min_df, alpha, and score for naive Bayes: 200 0.01 0.5891\n",
      "\tBest min_df, max_depth, and score for random forests: 300 4 0.5859\n",
      "\tBest min_df, C, and score for logistic regression: 100 0.01 0.5766\n",
      "Analyzing tweets at the author level: S/N\n",
      "\tBest min_df, alpha, and score for naive Bayes: 200 0.01 0.6594\n",
      "\tBest min_df, max_depth, and score for random forests: 50 3 0.6234\n",
      "\tBest min_df, C, and score for logistic regression: 50 0.01 0.5766\n",
      "Analyzing tweets at the author level: F/T\n",
      "\tBest min_df, alpha, and score for naive Bayes: 500 100.0 0.5969\n",
      "\tBest min_df, max_depth, and score for random forests: 200 3 0.6031\n",
      "\tBest min_df, C, and score for logistic regression: 200 0.01 0.5812\n",
      "Analyzing tweets at the author level: J/P\n",
      "\tBest min_df, alpha, and score for naive Bayes: 50 1.0 0.6\n",
      "\tBest min_df, max_depth, and score for random forests: 200 2 0.6\n",
      "\tBest min_df, C, and score for logistic regression: 200 0.01 0.5734\n",
      "\u0007Elapsed grid searching time: --- 23.9 minutes ---\n"
     ]
    }
   ],
   "source": [
    "stopwatch = TimeTracker.TimeTracker() # Don't include setup.\n",
    "test_size = 0.4\n",
    "min_dfs = [50, 100, 200, 300, 500]\n",
    "for letter_pair in letters:\n",
    "    test_letter = letter_pair[0]\n",
    "    print('Analyzing tweets at the author level:', end=' ')\n",
    "    print(f'{test_letter}/{letter_pair[1]}')\n",
    "    \n",
    "    best_min_df, best_alpha, best_test_score = 0, 0, 0\n",
    "    for min_df in min_dfs:\n",
    "        for alpha in np.power(10., np.arange(-2, 3)):\n",
    "            author_results = analyze_tweets(\n",
    "                tweets_per_author, letter=test_letter, classifier=NAIVE_BAYES,\n",
    "                min_df=min_df, alpha=alpha, test_size=test_size)\n",
    "            train_score, test_score = round(author_results[0], 4),\\\n",
    "                round(author_results[1], 4)\n",
    "            if test_score > best_test_score:\n",
    "                best_min_df, best_alpha, best_test_score\\\n",
    "                    = min_df, alpha, test_score\n",
    "    print('\\tBest min_df, alpha, and score for naive Bayes:',\n",
    "          best_min_df, best_alpha, best_test_score)\n",
    "\n",
    "    best_min_df, best_max_depth, best_test_score = 0, 0, 0\n",
    "    for min_df in min_dfs:\n",
    "        for max_depth in [2, 3, 4, 5]:\n",
    "            author_results = analyze_tweets(\n",
    "                tweets_per_author, letter=test_letter, classifier=RAND_FOREST,\n",
    "                min_df=min_df, max_depth=max_depth, test_size=test_size)\n",
    "            train_score, test_score = round(author_results[0], 4),\\\n",
    "                round(author_results[1], 4)\n",
    "            if test_score > best_test_score:\n",
    "                best_min_df, best_max_depth, best_test_score\\\n",
    "                    = min_df, max_depth, test_score\n",
    "    print('\\tBest min_df, max_depth, and score for random forests:',\n",
    "          best_min_df, best_max_depth, best_test_score)\n",
    "\n",
    "    best_min_df, best_C, best_test_score = 0, 0, 0\n",
    "    for min_df in min_dfs:\n",
    "        for C in np.power(10., np.arange(-2, 3)):\n",
    "            author_results = analyze_tweets(\n",
    "                tweets_per_author, letter=test_letter, classifier=LOGISTIC,\n",
    "                min_df=min_df, C=C, test_size=test_size, max_iter=1e4)\n",
    "            train_score, test_score = round(author_results[0], 4),\\\n",
    "                round(author_results[1], 4)\n",
    "            if test_score > best_test_score:\n",
    "                best_min_df, best_C, best_test_score\\\n",
    "                    = min_df, C, test_score\n",
    "    print('\\tBest min_df, C, and score for logistic regression:',\n",
    "          best_min_df, best_C, best_test_score)\n",
    "\n",
    "print('\\aElapsed grid searching time: ' + stopwatch.getElapsedTime())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In most cases, naive Bayes fares the best, and in the one case where random\n",
    "forests edges it out, the difference is minor. Let's repeat the process, this\n",
    "time over just the naive Bayes and see what our results are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analyzing tweets at the author level: E/I\n",
      "\tmin_df=50, alpha=0.01, train score=0.8188, test score=0.5734\n",
      "\tmin_df=50, alpha=0.1, train score=0.8188, test score=0.5734\n",
      "\tmin_df=50, alpha=1.0, train score=0.8177, test score=0.5734\n",
      "\tmin_df=50, alpha=10.0, train score=0.8083, test score=0.575\n",
      "\tmin_df=50, alpha=100.0, train score=0.7729, test score=0.5812\n",
      "\tmin_df=100, alpha=0.01, train score=0.7729, test score=0.5812\n",
      "\tmin_df=100, alpha=0.1, train score=0.7729, test score=0.5812\n",
      "\tmin_df=100, alpha=1.0, train score=0.7719, test score=0.5812\n",
      "\tmin_df=100, alpha=10.0, train score=0.7688, test score=0.5859\n",
      "\tmin_df=100, alpha=100.0, train score=0.7479, test score=0.5781\n",
      "\tmin_df=200, alpha=0.01, train score=0.7271, test score=0.5891\n",
      "\tmin_df=200, alpha=0.1, train score=0.7271, test score=0.5891\n",
      "\tmin_df=200, alpha=1.0, train score=0.726, test score=0.5891\n",
      "\tmin_df=200, alpha=10.0, train score=0.7219, test score=0.5875\n",
      "\tmin_df=200, alpha=100.0, train score=0.7031, test score=0.575\n",
      "\tmin_df=300, alpha=0.01, train score=0.6896, test score=0.5766\n",
      "\tmin_df=300, alpha=0.1, train score=0.6896, test score=0.5766\n",
      "\tmin_df=300, alpha=1.0, train score=0.6896, test score=0.5781\n",
      "\tmin_df=300, alpha=10.0, train score=0.6854, test score=0.5781\n",
      "\tmin_df=300, alpha=100.0, train score=0.675, test score=0.5688\n",
      "\tmin_df=500, alpha=0.01, train score=0.6708, test score=0.5812\n",
      "\tmin_df=500, alpha=0.1, train score=0.6708, test score=0.5812\n",
      "\tmin_df=500, alpha=1.0, train score=0.6708, test score=0.5812\n",
      "\tmin_df=500, alpha=10.0, train score=0.6708, test score=0.5781\n",
      "\tmin_df=500, alpha=100.0, train score=0.6635, test score=0.575\n",
      "Best min_df, alpha, and score for E: 200 0.01 0.5891\n",
      "\n",
      "Analyzing tweets at the author level: S/N\n",
      "\tmin_df=50, alpha=0.01, train score=0.7583, test score=0.6469\n",
      "\tmin_df=50, alpha=0.1, train score=0.7583, test score=0.6469\n",
      "\tmin_df=50, alpha=1.0, train score=0.7573, test score=0.6469\n",
      "\tmin_df=50, alpha=10.0, train score=0.7531, test score=0.6484\n",
      "\tmin_df=50, alpha=100.0, train score=0.6719, test score=0.6031\n",
      "\tmin_df=100, alpha=0.01, train score=0.7156, test score=0.6484\n",
      "\tmin_df=100, alpha=0.1, train score=0.7156, test score=0.6484\n",
      "\tmin_df=100, alpha=1.0, train score=0.7156, test score=0.6484\n",
      "\tmin_df=100, alpha=10.0, train score=0.7104, test score=0.6438\n",
      "\tmin_df=100, alpha=100.0, train score=0.6771, test score=0.6109\n",
      "\tmin_df=200, alpha=0.01, train score=0.6802, test score=0.6594\n",
      "\tmin_df=200, alpha=0.1, train score=0.6802, test score=0.6594\n",
      "\tmin_df=200, alpha=1.0, train score=0.6792, test score=0.6594\n",
      "\tmin_df=200, alpha=10.0, train score=0.6792, test score=0.6594\n",
      "\tmin_df=200, alpha=100.0, train score=0.6698, test score=0.6156\n",
      "\tmin_df=300, alpha=0.01, train score=0.6719, test score=0.6375\n",
      "\tmin_df=300, alpha=0.1, train score=0.6708, test score=0.6375\n",
      "\tmin_df=300, alpha=1.0, train score=0.674, test score=0.6375\n",
      "\tmin_df=300, alpha=10.0, train score=0.6698, test score=0.6406\n",
      "\tmin_df=300, alpha=100.0, train score=0.6625, test score=0.6109\n",
      "\tmin_df=500, alpha=0.01, train score=0.6615, test score=0.6406\n",
      "\tmin_df=500, alpha=0.1, train score=0.6615, test score=0.6406\n",
      "\tmin_df=500, alpha=1.0, train score=0.6615, test score=0.6406\n",
      "\tmin_df=500, alpha=10.0, train score=0.6635, test score=0.6422\n",
      "\tmin_df=500, alpha=100.0, train score=0.6625, test score=0.6344\n",
      "Best min_df, alpha, and score for S: 200 0.01 0.6594\n",
      "\n",
      "Analyzing tweets at the author level: F/T\n",
      "\tmin_df=50, alpha=0.01, train score=0.726, test score=0.5812\n",
      "\tmin_df=50, alpha=0.1, train score=0.726, test score=0.5797\n",
      "\tmin_df=50, alpha=1.0, train score=0.725, test score=0.5797\n",
      "\tmin_df=50, alpha=10.0, train score=0.7125, test score=0.5734\n",
      "\tmin_df=50, alpha=100.0, train score=0.6844, test score=0.5781\n",
      "\tmin_df=100, alpha=0.01, train score=0.6875, test score=0.5828\n",
      "\tmin_df=100, alpha=0.1, train score=0.6875, test score=0.5844\n",
      "\tmin_df=100, alpha=1.0, train score=0.6885, test score=0.5828\n",
      "\tmin_df=100, alpha=10.0, train score=0.6885, test score=0.5859\n",
      "\tmin_df=100, alpha=100.0, train score=0.6771, test score=0.5828\n",
      "\tmin_df=200, alpha=0.01, train score=0.675, test score=0.5953\n",
      "\tmin_df=200, alpha=0.1, train score=0.675, test score=0.5953\n",
      "\tmin_df=200, alpha=1.0, train score=0.674, test score=0.5953\n",
      "\tmin_df=200, alpha=10.0, train score=0.6698, test score=0.5938\n",
      "\tmin_df=200, alpha=100.0, train score=0.6615, test score=0.5922\n",
      "\tmin_df=300, alpha=0.01, train score=0.65, test score=0.5938\n",
      "\tmin_df=300, alpha=0.1, train score=0.65, test score=0.5938\n",
      "\tmin_df=300, alpha=1.0, train score=0.65, test score=0.5938\n",
      "\tmin_df=300, alpha=10.0, train score=0.65, test score=0.5906\n",
      "\tmin_df=300, alpha=100.0, train score=0.6469, test score=0.5875\n",
      "\tmin_df=500, alpha=0.01, train score=0.6448, test score=0.5953\n",
      "\tmin_df=500, alpha=0.1, train score=0.6448, test score=0.5953\n",
      "\tmin_df=500, alpha=1.0, train score=0.6448, test score=0.5953\n",
      "\tmin_df=500, alpha=10.0, train score=0.6438, test score=0.5953\n",
      "\tmin_df=500, alpha=100.0, train score=0.6458, test score=0.5969\n",
      "Best min_df, alpha, and score for F: 500 100.0 0.5969\n",
      "\n",
      "Analyzing tweets at the author level: J/P\n",
      "\tmin_df=50, alpha=0.01, train score=0.6896, test score=0.5984\n",
      "\tmin_df=50, alpha=0.1, train score=0.6896, test score=0.5984\n",
      "\tmin_df=50, alpha=1.0, train score=0.6885, test score=0.6\n",
      "\tmin_df=50, alpha=10.0, train score=0.6812, test score=0.5969\n",
      "\tmin_df=50, alpha=100.0, train score=0.6583, test score=0.6\n",
      "\tmin_df=100, alpha=0.01, train score=0.6615, test score=0.5844\n",
      "\tmin_df=100, alpha=0.1, train score=0.6615, test score=0.5828\n",
      "\tmin_df=100, alpha=1.0, train score=0.6615, test score=0.5828\n",
      "\tmin_df=100, alpha=10.0, train score=0.6604, test score=0.5812\n",
      "\tmin_df=100, alpha=100.0, train score=0.6479, test score=0.5891\n",
      "\tmin_df=200, alpha=0.01, train score=0.651, test score=0.5797\n",
      "\tmin_df=200, alpha=0.1, train score=0.651, test score=0.5797\n",
      "\tmin_df=200, alpha=1.0, train score=0.651, test score=0.5781\n",
      "\tmin_df=200, alpha=10.0, train score=0.6531, test score=0.5812\n",
      "\tmin_df=200, alpha=100.0, train score=0.6448, test score=0.5766\n",
      "\tmin_df=300, alpha=0.01, train score=0.6312, test score=0.575\n",
      "\tmin_df=300, alpha=0.1, train score=0.6312, test score=0.575\n",
      "\tmin_df=300, alpha=1.0, train score=0.6312, test score=0.5734\n",
      "\tmin_df=300, alpha=10.0, train score=0.6312, test score=0.5766\n",
      "\tmin_df=300, alpha=100.0, train score=0.6354, test score=0.5703\n",
      "\tmin_df=500, alpha=0.01, train score=0.6302, test score=0.5672\n",
      "\tmin_df=500, alpha=0.1, train score=0.6302, test score=0.5672\n",
      "\tmin_df=500, alpha=1.0, train score=0.6302, test score=0.5672\n",
      "\tmin_df=500, alpha=10.0, train score=0.6312, test score=0.5672\n",
      "\tmin_df=500, alpha=100.0, train score=0.6292, test score=0.5688\n",
      "Best min_df, alpha, and score for J: 50 1.0 0.6\n"
     ]
    }
   ],
   "source": [
    "min_dfs = [50, 100, 200, 300, 500]\n",
    "for letter_pair in letters:\n",
    "    test_letter = letter_pair[0]\n",
    "    print('\\nAnalyzing tweets at the author level:', end=' ')\n",
    "    print(f'{test_letter}/{letter_pair[1]}')\n",
    "    \n",
    "    best_min_df, best_alpha, best_test_score = 0, 0, 0\n",
    "    for min_df in min_dfs:\n",
    "        for alpha in np.power(10., np.arange(-2, 3)):\n",
    "            author_results = analyze_tweets(\n",
    "                tweets_per_author, letter=test_letter, classifier=NAIVE_BAYES,\n",
    "                min_df=min_df, alpha=alpha, test_size=test_size)\n",
    "            train_score, test_score = round(author_results[0], 4),\\\n",
    "                round(author_results[1], 4)\n",
    "            if test_score > best_test_score:\n",
    "                best_min_df, best_alpha, best_test_score\\\n",
    "                    = min_df, alpha, test_score\n",
    "            print(f'\\tmin_df={min_df}, alpha={alpha}, train score='\n",
    "                  + f'{train_score}, test score={test_score}')\n",
    "            \n",
    "    print(f'Best min_df, alpha, and score for {test_letter}:',\n",
    "          best_min_df, best_alpha, best_test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Low values of min_df badly overfit the data. These models probably rely\n",
    "on words that rarely show up and happen to particularly fit the given tweets\n",
    "but cannot be generalized well. However, we would like to keep min_df as low\n",
    "as possible to avoid throwing out too much. Furthermore, since the test scores\n",
    "do not vary much within each axis, we can select one set of hyperparameters\n",
    "for the whole test. That selection is min_df=200 and alpha=1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
